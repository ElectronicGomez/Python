{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV - Procesamiento de imagenes\n",
    "![](https://pyimagesearch.com/wp-content/uploads/2018/05/opencv_tutorial_header.jpg)\n",
    "\n",
    "Vamos a revisar algunos de las tareas que se pueden realizar con OpenCV respecto a imágenes y video, en cuanto a procesamiento y manipulación de los pixels.\n",
    "\n",
    "Luis A. Muñoz\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulación de imagenes\n",
    "Entre las tareas más básicas en el procesamiento de imágenes es la de modificar el tamaño de una imágen. Esto es una manipulación a nivel matricial realizado por OpenCV tanto de imagenes de gris (2D) e imágenes en color (3D)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 600, 3)\n",
      "(450, 600)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"img\\\\img1.jpg\", cv2.IMREAD_COLOR)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "print(img.shape)\n",
    "print(gray.shape)\n",
    "\n",
    "cv2.imshow(\"Imagen BGR\", img)\n",
    "cv2.imshow(\"Imagen Gray\", gray)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus App: Marko \"tres nombres\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    height, width, _ = frame.shape\n",
    "    \n",
    "    left = frame[:,:width//2,:]\n",
    "    right = cv2.flip(left, 1)\n",
    "    img = cv2.hconcat([left, right])\n",
    "    \n",
    "    cv2.imshow('Mirror Cam', img)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Region of Interest (ROI)\n",
    "La Región de Interés (ROI, por sus siglas en inglés) es un concepto en imágenes que hace referencia a la sección de una imágen donde se aplicará algún procesamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"img\\\\img1.jpg\", cv2.IMREAD_COLOR)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "img_roi = img[100:350,250:400,:] \n",
    "gray_roi = gray[100:350,250:400]\n",
    "\n",
    "cv2.imshow(\"Imagen BGR\", img_roi)\n",
    "cv2.imshow(\"Imagen Gray\", gray_roi)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dibujo de figuras con OpenCV\n",
    "Sobre una imágen o video se pueden superponer formas geometricas con ciertas funciones especiales de OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"img\\\\img2.jpg\", cv2.IMREAD_COLOR)\n",
    "cv2.line(img, (50, 100), (50, 400), (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow(\"Imagen\", img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"img\\\\img2.jpg\", cv2.IMREAD_COLOR)\n",
    "cv2.rectangle(img, (250, 120), (400, 300), (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow(\"Imagen\", img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"img\\\\img2.jpg\", cv2.IMREAD_COLOR)\n",
    "cv2.circle(img, (250, 400), 100, (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow(\"Imagen\", img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Blending (addWeighted)\n",
    "Se puede realizar una suma de imagenes, asignando un peso porcentual a cada imagen. Esto requiere que ambas imagenes tengan las mismas dimensiones y los mismos canales de colores (es decir, la misma forma). Los parametros de la formula (alpha, beta y gama) estan definidos para:\n",
    "\n",
    "$$dst = \\alpha * img1 + \\beta * img2 + \\gamma $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size img1: (469, 626, 3)\n",
      "Siza img2: (469, 626, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img1 = cv2.imread(\"img\\\\img3.jpg\", cv2.IMREAD_COLOR)\n",
    "print(\"Size img1:\", img1.shape)\n",
    "\n",
    "img2 = cv2.imread(\"img\\\\img4.jpg\", cv2.IMREAD_COLOR)\n",
    "img2 = cv2.resize(img2, (img1.shape[1], img1.shape[0]))    #cvs.resize(img, (ancho, alto))\n",
    "print(\"Siza img2:\", img2.shape)\n",
    "\n",
    "# cv.addWeighted(img1, alpha, img2, beta, gamma)\n",
    "img_photo = cv2.addWeighted(img1, 0.7, img2, 0.3, 0) \n",
    "cv2.imshow(\"Imagen\", img_photo)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "img = cv2.imread(\"img\\\\img5.jpg\")\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    height, width, _ = frame.shape\n",
    "    img = cv2.resize(img, (width, height))\n",
    "    \n",
    "    img_blended = cv2.addWeighted(img, 0.7, frame, 0.3, 0)\n",
    "    cv2.imshow('Img', img_blended)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operaciones lógicas (bitwise)\n",
    "Se puede realizar operaciones lógicas con los arreglos de imagenes a novel de OpenCV, asi como operaciones aritméticas. Con estas operaciones se pueden hacer tratamientos especiales a las imagenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img1 = cv2.imread(\"img\\\\upc_campus.jpg\", cv2.IMREAD_COLOR)\n",
    "img2 = cv2.imread(\"img\\\\upc_logo.jpg\", cv2.IMREAD_COLOR)\n",
    "img2 = cv2.resize(img2, (80, 80))\n",
    "roi = img1[-80:, -80:]\n",
    "\n",
    "cv2.imshow(\"img1\", img1)\n",
    "cv2.imshow(\"img2\", img2)\n",
    "\n",
    "# Se crea una mascara con la imagen del logo con un control de umbral (threshold)\n",
    "# y se invierte la imagen con una operacion logica (bitwise_not)\n",
    "img_gray= cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "ret, mask = cv2.threshold(img_gray, 128, 255, cv2.THRESH_BINARY)\n",
    "mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "cv2.imshow('mask', mask)\n",
    "cv2.imshow('mask_inv', mask_inv)\n",
    "\n",
    "# Hay que oscurecer los pixels que seran reemplazados por el logo (ROI)\n",
    "img_bg = cv2.bitwise_and(roi, roi, mask=mask)\n",
    "cv2.imshow(\"img1_bg\", img_bg)\n",
    "\n",
    "# Hay que tomar solo los puntos que conforman en logo (mascara)\n",
    "img_fg = cv2.bitwise_and(img2, img2, mask=mask_inv)\n",
    "cv2.imshow(\"img2_fg\", img_fg)\n",
    "\n",
    "# Hay que sumar ambas imagenes en el ROI\n",
    "dst = cv2.add(img_bg, img_fg)\n",
    "img1[-80:, -80:] = dst\n",
    "cv2.imshow(\"Imagen con logo\", img1)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def put_logo(img, logo, roi):\n",
    "    gray= cv2.cvtColor(logo, cv2.COLOR_BGR2GRAY)\n",
    "    ret, mask = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
    "    mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "    fondo = cv2.bitwise_and(roi, roi, mask=mask)\n",
    "    frente = cv2.bitwise_and(logo, logo, mask=mask_inv)\n",
    "\n",
    "    dst = cv2.add(fondo, frente)\n",
    "    img[-100:-20, -100:-20] = dst\n",
    "    \n",
    "    return img\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    logo = cv2.imread(\"img\\\\upc_logo.jpg\", cv2.IMREAD_COLOR)\n",
    "    logo = cv2.resize(logo, (80, 80))\n",
    "    roi = img[-100:-20, -100:-20]\n",
    "    \n",
    "    img_with_logo = put_logo(img, logo, roi)\n",
    "    \n",
    "    cv2.imshow(\"Video Logo\", img_with_logo)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mascaras con inRange (Deteccion de colores)\n",
    "![](https://i.stack.imgur.com/gyuw4.png)\n",
    "\n",
    "Se pueden confeccionar máscaras asociadas a un rango de valores de color, utilizado el modelo de color HSV (Hue, Saturation, Value) que permite detectar colores iluminados por luz natural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 57 238 255]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"img\\\\people_green_bg.jpg\", cv2.IMREAD_COLOR)\n",
    "img_bg = cv2.imread(\"img\\\\office_bg.jpg\", cv2.IMREAD_COLOR)\n",
    "img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "print(img_hsv[10, 10, :])    # HUE, SATURATION, VALUE\n",
    "\n",
    "lower_bound = np.array([40, 200, 255])\n",
    "upper_bound = np.array([85, 255, 255])\n",
    "mask = cv2.inRange(img_hsv, lower_bound, upper_bound)\n",
    "mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "mask = cv2.dilate(mask, kernel, iterations=1)\n",
    "mask_inv = cv2.erode(mask_inv, kernel, iterations=1)\n",
    "\n",
    "img_mask = cv2.bitwise_and(img, img, mask=mask_inv)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.imshow('mask', mask)\n",
    "cv2.imshow('img_mask', img_mask)\n",
    "\n",
    "roi = img_bg[-img_mask.shape[0]:,-img_mask.shape[1]:,:]\n",
    "img_bg2 = cv2.bitwise_and(roi, roi, mask=mask)\n",
    "\n",
    "dst = cv2.add(img_mask, img_bg2)\n",
    "cv2.imshow('Final', dst)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrado de imagenes\n",
    "Entre los procesos frecuentes de manipulación de imágenes esta el de filtrar una imágen, ya sea para reducír ruido como para hacer énfasis en ciertos elementos geométricos de una imágen con la objetivo de hacer que un proceso posterior sea más sencillo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"img\\img1.jpg\")\n",
    "img = cv2.resize(img, (300, 300))\n",
    "cv2.imshow(\"Imagen\", img)\n",
    "\n",
    "kernel = np.ones((5, 5), np.float32) / 25\n",
    "\n",
    "img_fil1 = cv2.filter2D(img, -1, kernel)\n",
    "img_fil2 = cv2.blur(img, (5, 5))\n",
    "img_fil3 = cv2.GaussianBlur(img, (7, 7), 0)\n",
    "\n",
    "cv2.imshow('Filter2D', img_fil1)\n",
    "cv2.imshow('Blur', img_fil2)\n",
    "cv2.imshow('Gaussian Blur', img_fil3)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"img\\img6.jpg\")\n",
    "img = cv2.resize(img, (400, 300))\n",
    "cv2.imshow(\"Imagen\", img)\n",
    "\n",
    "img_fil1 = cv2.medianBlur(img, 5)\n",
    "img_fil2 = cv2.bilateralFilter(img, 9, 75, 75)\n",
    "\n",
    "cv2.imshow(\"Median Blur\", img_fil1)\n",
    "cv2.imshow(\"Bilateral Filter\", img_fil2)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detección de bordes\n",
    "Existen filtros especiales que retornan resultados especiales, por ejemplo, un proceso de filtrado que retorna sobre los bordes de una imagen. OpenCV implementa un número de algoritmos para la detección de bordes. En este ejemplo se prueba el algoritmo de Canny (John F. Canny, 1986)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"img\\img1.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.resize(img, (400, 300))\n",
    "cv2.imshow(\"Imagen\", img)\n",
    "\n",
    "edges = cv2.Canny(img, 100, 200)\n",
    "cv2.imshow('edges', edges)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    edges = cv2.Canny(frame, 100, 200)\n",
    "    edges_inv = cv2.bitwise_not(edges)\n",
    "    \n",
    "    cv2.imshow('edges', edges_inv)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detección de esquinas\n",
    "Otro algoritmo útil de OpenCV es el algoritmo de detección de esquinas Shi-Tomashi (J. Shi and C. Tomasi, 1994) que busca pixels en donde la gradiente cambia en varias direcciones por encima de un valor de umbral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('img\\\\img7.jpg')\n",
    "img = cv2.resize(img, (600, 500))\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "corners = cv2.goodFeaturesToTrack(gray, 50, 0.01, 10)\n",
    "corners = np.int0(corners)\n",
    "\n",
    "for i in corners:\n",
    "    x,y = i.ravel()   # Convierte un array 2D en 1D\n",
    "    cv2.circle(img, (x,y), 3, (0, 0, 255), -1)\n",
    "\n",
    "cv2.imshow('Corners', img)\n",
    "    \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detección de contornos\n",
    "El algoritmo de detección de contornos busca pixel adyacentes que tengan las mismas propiedades. El algoritmo requiere un tratamiento inicial de la imágen para hacer más fácil la detección de los bordes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Se detectan objetos de color rojo, verde o azul\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "kernel_open = np.ones((30, 30))\n",
    "kernel_close = np.ones((100, 100))\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    img_hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    mask1 = cv2.inRange(img_hsv, (0,50,20), (5,255,255))   # Rango inferior rojo\n",
    "    mask2 = cv2.inRange(img_hsv, (175,50,20), (180,255,255))    # Rango superior rojo\n",
    "    mask = cv2.bitwise_or(mask1, mask2)\n",
    "    \n",
    "    # erosion + dilation: elimina puntos blancos\n",
    "    mask_open = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel_open)          \n",
    "    # dilation + erosion: elimina agujeros negros\n",
    "    mask_close = cv2.morphologyEx(mask_open, cv2.MORPH_CLOSE, kernel_close)\n",
    "    \n",
    "    mask_final = mask_close\n",
    "    \n",
    "    # Se hallan los contornos de la imagen (blanco sobre fondo negro)\n",
    "    conts, h = cv2.findContours(mask_final, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    cv2.drawContours(frame, conts, -1, (255, 0, 0), 3)\n",
    "    \n",
    "    for i in range(len(conts)):\n",
    "        x, y, w, h = cv2.boundingRect(conts[i])\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "           \n",
    "    cv2.imshow(\"WebCam\", frame)\n",
    "    cv2.imshow(\"Mask Final\", mask_final)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insertar texto en OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"img\\\\img1.jpg\", cv2.IMREAD_COLOR)\n",
    "cv2.rectangle(img, (260, 120),(380, 300), (0, 0, 255), 2)\n",
    "cv2.rectangle(img, (260, 100), (320, 120), (0, 0, 255), -1)\n",
    "cv2.putText(img, \"Tulipan\", (260, 115), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "\n",
    "cv2.imshow(\"Imagen BGR\", img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FONT_HERSHEY_COMPLEX\n",
      "FONT_HERSHEY_COMPLEX_SMALL\n",
      "FONT_HERSHEY_DUPLEX\n",
      "FONT_HERSHEY_PLAIN\n",
      "FONT_HERSHEY_SCRIPT_COMPLEX\n",
      "FONT_HERSHEY_SCRIPT_SIMPLEX\n",
      "FONT_HERSHEY_SIMPLEX\n",
      "FONT_HERSHEY_TRIPLEX\n",
      "FONT_ITALIC\n",
      "QT_FONT_BLACK\n",
      "QT_FONT_BOLD\n",
      "QT_FONT_DEMIBOLD\n",
      "QT_FONT_LIGHT\n",
      "QT_FONT_NORMAL\n"
     ]
    }
   ],
   "source": [
    "fonts = [i for i in dir(cv2) if 'FONT' in i]\n",
    "for font in fonts: print(font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Haar Cascade Detection - Detección de rostros\n",
    "La detección de objetos utilizando un clasificador de cascada de propiedades (Haar Cascade feature-based detection) es un método de detección efectivo propuesto por Paul Viola y Michael Jones en 2001. Es una aproximación basada en Machine Learning donde una función cascada es entrenada de una muestra de imágenes positivas y negativas. \n",
    "\n",
    "Para detectar un rostro, el algoritmo necesita muchas imágenes positivas y negativas para el entrenamiento del modelo clasificador. Lo que hace el algoritmo es extraer las características de un rostro. Para esto se parte un conjunto de caracteristicas: patrones de zonas oscuras e iluminadas que operarán como kernels de convolución.\n",
    "\n",
    "![](https://docs.opencv.org/3.4/haar_features.jpg)\n",
    "\n",
    "Con estas características se genera un modelo de rostro que va acumulando las diferentes caracteristicas en estados, de tal forma que en lugar de hacer un proceso complejo de revisar los detalles de una imagen, se hacen varios pasos simples de detección de cada una de las características de un rostro, en una especie de cascada de propiedades, en donde una imágen pasa de estado \"puede ser un rostro\" a \"es un rostro\" o \"no es un rostro\", dependiendo si va acumulando características del modelo generado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "smile_cascade = cv2.CascadeClassifier(\"haarcascade_smile.xml\")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(gray, 1.2, 5)   # imagen(gray), escala, # min vecinos\n",
    "    \n",
    "    for x, y, w, h in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        \n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "        \n",
    "        smiles = smile_cascade.detectMultiScale(roi_gray, 1.12, 18)\n",
    "        \n",
    "        for sx, sy, sw, sh in smiles:\n",
    "            cv2.rectangle(roi_color, (sx, sy), (sx+sw, sy+sh), (0, 0, 255), 2)\n",
    "       \n",
    "    \n",
    "    cv2.imshow('WebCam', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio\n",
    "Automatice el kiosko de fotos en tkinter para que pueda tomar fotografias de forma automática cuando todas las personas frente a la camara se encuentren mirando a la cámara y sonriendo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
